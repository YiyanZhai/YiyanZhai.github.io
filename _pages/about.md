---
permalink: /
title: "Hi, I'm Yiyan Zhai :)"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I recently graduated from Carnegie Mellon University (B.S. in CS, minor in ML) and am **applying to PhD programs for Fall 2026**! My research interests lie at building efficient and scalable ML systems.

I have been working with with Prof. [Tianqi Chen](https://tqchen.com/) at CMU Catalyst Group on:
* **[FlashInfer-Bench](https://github.com/flashinfer-ai/flashinfer-bench)**, a kernel benchmarking loop that goes from kernel generation → evaluation → drop-in replacement in serving stacks (FlashInfer/SGLang/vLLM).
* **[WebLLM Assistant](https://github.com/mlc-ai/web-llm-assistant)**, which integrates Overleaf and Google Workspace with in-browser agents using [WebLLM](https://github.com/mlc-ai/web-llm).
<!-- * [WebLLM](https://github.com/mlc-ai/web-llm): enabling local LLM inference directly in the browser. -->

I am also fortunate to collaborate with Prof. [Juncheng Yang](https://junchengyang.com/) at Harvard SEAS on:
* **Cache replacement algorithms** for real-world enterprise storage systems (VMware vSAN)
* **Resilient routing for LLM inference**